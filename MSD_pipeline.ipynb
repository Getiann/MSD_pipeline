{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a4e28c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "from utils import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4030ce2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "design_name = \"test\"\n",
    "work_dir = \"/home/ge/app/MSD_design/test\"\n",
    "pdbs_dir = \"/home/ge/app/MSD_design/test/pdbs\"\n",
    "seed = 111\n",
    "fixed_pos = \"A207 A208\"\n",
    "designed_seqs_num = 100\n",
    "\n",
    "MPNN_path = \"/home/ge/app/MSD_design/LigandMPNN_MSD/run.py\"\n",
    "run_mpnn_msd_env = \"/data/ge/conda/envs/mpnn_env\"\n",
    "\n",
    "ret_params = \"/home/ge/app/MSD_design/test/RET.params\"\n",
    "\n",
    "run_af3_env = \"/venv/alphafold3_venv/bin/activate\"\n",
    "run_af3_py = \"/home/ge/app/MSD_design/run_alphafold.py\"\n",
    "\n",
    "run_only_con_env = \"/data/ge/conda/envs/alphafold3\"\n",
    "run_only_con_py = \"/home/ge/app/MSD_design/run_only_confidence1.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653a7833",
   "metadata": {},
   "source": [
    "- design_name  \n",
    "---|pdbs                # 所有的state结构，基于这些state去设计序列  \n",
    "---|designed_sequences  # 设计序列的保存路径  \n",
    "------|packed           # 同一个序列不同结构的packed结果（pyrosetta）  \n",
    "------|seqs             # 设计的MSD序列  \n",
    "---|run_af3             # 运行完整的single sequence af3的结果路径  \n",
    "---|run_only_con        # 只运行confidence head的结果路径"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea992eb2",
   "metadata": {},
   "source": [
    "# MSD design sequences\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b3a865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# more states pdb to design\n",
    "pdbs = glob.glob(f'{pdbs_dir}/*.pdb')\n",
    "dic = {}\n",
    "for pdb in pdbs:\n",
    "    pdb_name = pdb.split(\"/\")[-1].split(\".\")[0]\n",
    "    dic[pdb] = pdb_name\n",
    "with open(f\"{pdbs_dir}/multi.json\", \"w\") as f:\n",
    "    json.dump(dic, f, indent=4)\n",
    "\n",
    "MSD_bash_file = f\"{work_dir}/MSD_design_sequences.sh\"\n",
    "MSD_out = f\"{work_dir}/designed_sequences\"\n",
    "if os.path.exists(MSD_out):\n",
    "    shutil.rmtree(MSD_out)\n",
    "else:\n",
    "    os.mkdir(MSD_out)\n",
    "\n",
    "with open(MSD_bash_file, \"w\") as f:\n",
    "    f.write(f\"\"\"#!/bin/bash\n",
    "source /opt/conda/etc/profile.d/conda.sh\n",
    "conda activate {run_mpnn_msd_env}\n",
    "python {MPNN_path} \\\\\n",
    "    --seed 111 \\\\\n",
    "    --pdb_path_multi \"{pdbs_dir}/multi.json\" \\\\\n",
    "    --out_folder \"{MSD_out}\" \\\\\n",
    "    --multistate_design True  \\\\\n",
    "    --number_of_batches {designed_seqs_num} \\\\\n",
    "    --fixed_residues \"{fixed_pos}\"\n",
    "\"\"\")\n",
    "# os.chmod(MSD_bash_file, 0o755)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daa08dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "! bash MSD_design_sequences.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9e8067c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_file = glob.glob(f\"{MSD_out}/seqs/*.fa\")[0]\n",
    "designed_seqs = {}\n",
    "with open(fa_file, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for i in range(3, len(lines), 2):\n",
    "        la = lines[i-1].strip().split(\">\")[1]\n",
    "        seq_name = f\"{design_name}_{la.split('id=')[1].split(',')[0]}\"\n",
    "        designed_seqs[seq_name] = lines[i].strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a36af7",
   "metadata": {},
   "source": [
    "# Pyrosetta packed structures\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b1f983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrosetta\n",
    "from pyrosetta import pose_from_pdb\n",
    "from pyrosetta.rosetta.core.chemical import TypeSetMode\n",
    "from pyrosetta.rosetta.core.pack.task import TaskFactory\n",
    "from pyrosetta.rosetta.core.conformation import ResidueFactory\n",
    "from pyrosetta.rosetta.core.pack.task.operation import InitializeFromCommandline, RestrictToRepacking\n",
    "from pyrosetta.rosetta.protocols.minimization_packing import PackRotamersMover\n",
    "aa1_to_aa3 = {\n",
    "    \"A\": \"ALA\", \"R\": \"ARG\", \"N\": \"ASN\", \"D\": \"ASP\",\n",
    "    \"C\": \"CYS\", \"Q\": \"GLN\", \"E\": \"GLU\", \"G\": \"GLY\",\n",
    "    \"H\": \"HIS\", \"I\": \"ILE\", \"L\": \"LEU\", \"K\": \"LYS\",\n",
    "    \"M\": \"MET\", \"F\": \"PHE\", \"P\": \"PRO\", \"S\": \"SER\",\n",
    "    \"T\": \"THR\", \"W\": \"TRP\", \"Y\": \"TYR\", \"V\": \"VAL\"\n",
    "}\n",
    "extra_res_fa = \"\"\n",
    "params = [ret_params]\n",
    "if len(params) > 0:\n",
    "    extra_res_fa = \"-extra_res_fa\"\n",
    "    for p in params:\n",
    "        extra_res_fa += \" \" + p\n",
    "pyrosetta.init(f\"{extra_res_fa}\")\n",
    "\n",
    "def pack_sequence_on_backbone(pdb_file, sequence, scorefxn_name=\"ref2015\",out_file=\"packed_output.pdb\"):\n",
    "    pose = pose_from_pdb(pdb_file)\n",
    "    rts = pose.residue_type_set_for_pose(TypeSetMode.FULL_ATOM_t)\n",
    "\n",
    "    for i, aa in enumerate(sequence, start=1):\n",
    "        resname3 = aa1_to_aa3[aa]\n",
    "        new_res = ResidueFactory.create_residue(rts.name_map(resname3))\n",
    "        pose.replace_residue(i, new_res, True)\n",
    "    tf = TaskFactory()\n",
    "    tf.push_back(InitializeFromCommandline())\n",
    "    tf.push_back(RestrictToRepacking())\n",
    "\n",
    "    scorefxn = pyrosetta.create_score_function(scorefxn_name)\n",
    "    packer = PackRotamersMover(scorefxn)\n",
    "    packer.task_factory(tf)\n",
    "    packer.apply(pose)\n",
    "    pose.dump_pdb(out_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05efa2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "packed_dir = f\"{MSD_out}/packed\"\n",
    "for seqs_name, seqs in designed_seqs.items():\n",
    "    for pdb in pdbs:\n",
    "        pdb_name = pdb.split(\"/\")[-1].split(\".\")[0]\n",
    "        packed_pdb_file = f\"{packed_dir}/{seqs_name}__{pdb_name}.pdb\"\n",
    "        pack_sequence_on_backbone(pdb, seqs, out_file=packed_pdb_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de58e548",
   "metadata": {},
   "source": [
    "# Run af3 single-sequence (to get plddt_0)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7931e53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run af3\n",
    "af3_dir = f\"{work_dir}/run_af3\"\n",
    "if os.path.exists(af3_dir):\n",
    "    shutil.rmtree(af3_dir)\n",
    "    os.mkdir(af3_dir)\n",
    "else:\n",
    "    os.mkdir(af3_dir)\n",
    "\n",
    "af3_input_json_dir = f\"{af3_dir}/input_json\"\n",
    "if os.path.exists(af3_input_json_dir):\n",
    "    shutil.rmtree(af3_input_json_dir)\n",
    "    os.mkdir(af3_input_json_dir)\n",
    "else:\n",
    "    os.mkdir(af3_input_json_dir)\n",
    "for seqs_name, seq in designed_seqs.items():\n",
    "    json_dic = af3_json(pdb_sequence=seq, chain_id=['A'], name=seqs_name, seed=[1], single=True, ligandccd=['RET'], ligand_id=['B'], modify=None)\n",
    "    json_file = f\"{af3_input_json_dir}/{seqs_name}.json\"\n",
    "    with open(json_file, \"w\") as f:\n",
    "        json.dump(json_dic, f, indent=4)\n",
    "\n",
    "out_dir = f\"{af3_dir}/outputs\"\n",
    "if os.path.exists(out_dir):\n",
    "    shutil.rmtree(out_dir)\n",
    "else:\n",
    "    os.mkdir(out_dir)\n",
    "af3_bash_file = f\"{work_dir}/run_af3.sh\"\n",
    "with open(af3_bash_file, \"w\") as f:\n",
    "    f.write(f\"\"\"#!/bin/bash\n",
    "source \"{run_af3_env}\"\n",
    "python {run_af3_py} \\\\\n",
    "    --input_dir=\"{af3_input_json_dir}\" \\\\\n",
    "    --model_dir=\"/data/share/alphafold3\"  \\\\\n",
    "    --output_dir=\"{out_dir}\" \\\\\n",
    "    --max_template_date=\"9999-01-01\" \\\\\n",
    "    --run_data_pipeline=False\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339cb162",
   "metadata": {},
   "outputs": [],
   "source": [
    "! bash run_af3.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4c5d33d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "af3_plddt_dic={}\n",
    "af3_dir = f\"{work_dir}/run_af3\"\n",
    "out_dir = f\"{af3_dir}/outputs\"\n",
    "plddt_files = glob.glob(f\"{out_dir}/*/*confidences.json\")\n",
    "plddt_files = [i for i in plddt_files if \"summary\" not in i]\n",
    "for plddt_file in plddt_files:\n",
    "    with open(plddt_file, \"r\") as f:\n",
    "        plddt_data = json.load(f)\n",
    "        name = plddt_file.split(\"/\")[-2]\n",
    "        af3_plddt_dic[name] = np.mean(plddt_data[\"atom_plddts\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b276bd",
   "metadata": {},
   "source": [
    "# Cacultate cross entropy loss in distogram\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dbbfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "packed_pdbs = glob.glob(f\"{packed_dir}/*.pdb\")\n",
    "dist_loss = {}\n",
    "dist_logits_files = glob.glob(f\"{out_dir}/*/distogram_logits.npz\")\n",
    "for packed_pdb in packed_pdbs:\n",
    "    packed_pdb_name = packed_pdb.split(\"/\")[-1].split(\".\")[0]\n",
    "    seq_name = packed_pdb_name.split(\"__\")[0]\n",
    "    for dist_logits_file in dist_logits_files:\n",
    "        dist_seq_name = dist_logits_file.split(\"/\")[-2]\n",
    "        if seq_name == dist_seq_name:\n",
    "            data = np.load(dist_logits_file)\n",
    "    dist_logits = data['distogram_logits']\n",
    "    num_tokens = data['num_tokens']\n",
    "    dist_logits = dist_logits[:num_tokens, :num_tokens,:]\n",
    "    gt_pos = pdb_to_tensor(packed_pdb)\n",
    "    mask = np.ones(gt_pos.shape[0])\n",
    "    assert dist_logits.shape[0] == gt_pos.shape[0], \"Distogram logits and ground truth positions must have the same number of residues.\"\n",
    "    loss = distogram_loss(dist_logits, gt_pos, mask)\n",
    "    dist_loss[packed_pdb_name] = loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7862ec3d",
   "metadata": {},
   "source": [
    "# Run only confidence head (to get plddt_1 plddt_2)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a9d456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run only confidence\n",
    "only_con_dir = f\"{work_dir}/run_only_con\"\n",
    "if os.path.exists(only_con_dir):\n",
    "    shutil.rmtree(only_con_dir)\n",
    "    os.mkdir(only_con_dir)\n",
    "else:\n",
    "    os.mkdir(only_con_dir)\n",
    "\n",
    "only_con_sh = f\"{work_dir}/run_only_con.sh\"\n",
    "only_input_dir = f\"{only_con_dir}/input_json\"\n",
    "if not os.path.exists(only_input_dir):\n",
    "    os.mkdir(only_input_dir)\n",
    "\n",
    "only_output_dir = f\"{only_con_dir}/outputs\"\n",
    "packed_pdbs = glob.glob(f\"{packed_dir}/*.pdb\")\n",
    "for pdb in packed_pdbs:\n",
    "    packed_name = pdb.split(\"/\")[-1].split(\".\")[0]\n",
    "    seq_name = packed_name.split(\"__\")[0]\n",
    "    json_dic = af3_json(pdb_sequence=designed_seqs[seq_name], chain_id=['A'], name=packed_name, seed=[1], single=True, ligandccd=['RET'], ligand_id=['B'], modify=None)\n",
    "    json_file = f\"{only_input_dir}/{packed_name}.json\"\n",
    "    with open(json_file, \"w\") as f:\n",
    "        json.dump(json_dic, f, indent=4)\n",
    "\n",
    "\n",
    "with open(only_con_sh, \"w\") as f:\n",
    "    f.write(f\"\"\"#!/bin/bash\n",
    "source /opt/conda/etc/profile.d/conda.sh\n",
    "conda activate {run_only_con_env}\n",
    "INPUT_JSON=\"{only_input_dir}\"\n",
    "INPUT_PDB=\"{packed_dir}\"\n",
    "for pdb_file in \"$INPUT_PDB\"/*.pdb; do\n",
    "    filename=$(basename \"$pdb_file\" .pdb)\n",
    "    json_file=\"$INPUT_JSON/$filename.json\"\n",
    "    if [[ -f \"$json_file\" ]]; then\n",
    "        echo \"Processing $filename\"\n",
    "        python {run_only_con_py} \\\\\n",
    "        --json_path=\"$json_file\" \\\\\n",
    "        --model_dir=\"/data/share/alphafold3\" \\\\\n",
    "        --output_dir=\"{only_output_dir}\" \\\\\n",
    "        --max_template_date=\"9999-01-01\" \\\\\n",
    "        --run_data_pipeline=False \\\\\n",
    "        --structure_pdb_path=\"$pdb_file\"\n",
    "    else\n",
    "        echo \"JSON file $json_file does not exist for $filename\"\n",
    "    fi\n",
    "done\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b053d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "! bash run_only_con.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aebb0923",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_con_plddt = glob.glob(f\"{only_output_dir}/*/*_atomplddt.json\")\n",
    "only_con_plddt_dic = {}\n",
    "for plddt_file in only_con_plddt:\n",
    "    with open(plddt_file, \"r\") as f:\n",
    "        plddt_data = json.load(f)\n",
    "        name = plddt_file.split(\"/\")[-2]\n",
    "        only_con_plddt_dic[name] = np.mean(plddt_data[\"atom_plddts\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bde072b",
   "metadata": {},
   "source": [
    "# Integrate all information\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926d7dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计所有信息，每个序列有三个plddt，两个loss\n",
    "total_info ={}\n",
    "for seqs_name in designed_seqs.keys():\n",
    "    total_info[seqs_name] = {}\n",
    "    total_info[seqs_name][\"seq\"] = designed_seqs[seqs_name]\n",
    "    total_info[seqs_name][\"plddt_0\"] = af3_plddt_dic.get(f\"{seqs_name}\", None)\n",
    "    for key, value in only_con_plddt_dic.items():\n",
    "        if key.startswith(seqs_name):\n",
    "            if \"plddt_1_2\" not in total_info[seqs_name]:\n",
    "                total_info[seqs_name][\"plddt_1_2\"] = [value]\n",
    "                total_info[seqs_name][\"dist_loss_1_2\"] = [float(dist_loss.get(key, None))]\n",
    "            else:\n",
    "                total_info[seqs_name][\"plddt_1_2\"].append(value)\n",
    "                total_info[seqs_name][\"dist_loss_1_2\"].append(float(dist_loss.get(key, None)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b5eb179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_info_file = f\"{work_dir}/total_info.json\"\n",
    "with open(total_info_file, \"w\") as f:\n",
    "    json.dump(total_info, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mpnn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
